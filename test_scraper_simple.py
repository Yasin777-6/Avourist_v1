"""
Simple test for –ö–æ–ê–ü scraper (no Django dependencies)
"""
import requests
from bs4 import BeautifulSoup
import re


def test_scrape_article(article_num="12.8"):
    """Test scraping a specific article"""
    print(f"\n{'='*60}")
    print(f"Testing –ö–æ–ê–ü Scraper for Article {article_num}")
    print(f"{'='*60}\n")
    
    url = "https://www.consultant.ru/document/cons_doc_LAW_34661/"
    
    try:
        print(f"üì° Fetching from: {url}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        print(f"‚úÖ Response received: {response.status_code}")
        print(f"üìÑ Content length: {len(response.text)} bytes\n")
        
        # Parse HTML
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Search for article in full text
        print(f"üîç Searching for article {article_num}...")
        
        full_text = soup.get_text()
        
        # Find article position
        article_patterns = [
            f'–°—Ç–∞—Ç—å—è {article_num}.',
            f'–°—Ç–∞—Ç—å—è {article_num} ',
            f'—Å—Ç. {article_num}',
            f'—Å—Ç.{article_num}',
        ]
        
        article_pos = -1
        for pattern in article_patterns:
            article_pos = full_text.find(pattern)
            if article_pos != -1:
                print(f"‚úÖ Found article at position {article_pos}")
                break
        
        if article_pos == -1:
            print(f"‚ùå Article {article_num} not found in page")
            print(f"\nüìù Sample content (first 1000 chars):")
            print(full_text[:1000])
            return
        
        # Extract text around article (next 2000 chars should contain punishment)
        article_section = full_text[article_pos:article_pos + 2000]
        
        print(f"\nüìã Article section found:")
        print("-" * 60)
        print(article_section[:500])
        print("-" * 60)
        
        # Extract fine with better patterns
        print(f"\nüí∞ Extracting fine...")
        fine_patterns = [
            r'—à—Ç—Ä–∞—Ñ.*?–≤ —Ä–∞–∑–º–µ—Ä–µ.*?(\d+)\s*—Ç—ã—Å—è—á',
            r'—à—Ç—Ä–∞—Ñ.*?(\d+)\s*—Ç—ã—Å—è—á.*?—Ä—É–±–ª–µ–π',
            r'–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–π —à—Ç—Ä–∞—Ñ.*?(\d+)\s*—Ç—ã—Å—è—á',
            r'–Ω–∞–ª–æ–∂–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —à—Ç—Ä–∞—Ñ–∞.*?(\d+)\s*—Ç—ã—Å—è—á',
            r'—à—Ç—Ä–∞—Ñ.*?(\d{2,6})\s*—Ä—É–±–ª–µ–π',
        ]
        
        fine_found = False
        for pattern in fine_patterns:
            match = re.search(pattern, article_section, re.IGNORECASE | re.DOTALL)
            if match:
                amount_str = match.group(1).replace(' ', '')
                try:
                    amount = int(amount_str)
                    # If it's in thousands, multiply
                    if '—Ç—ã—Å—è—á' in match.group(0).lower():
                        amount = amount * 1000
                    print(f"   ‚úÖ Fine: {amount:,} ‚ÇΩ".replace(',', ' '))
                    fine_found = True
                    break
                except:
                    pass
        
        if not fine_found:
            print(f"   ‚ùå Could not extract fine amount")
        
        # Extract license suspension
        print(f"\nüö´ Extracting license suspension...")
        license_patterns = [
            r'–ª–∏—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.*?–Ω–∞ —Å—Ä–æ–∫.*?–æ—Ç\s*(\d+\.?\d*)\s*–¥–æ\s*(\d+\.?\d*)\s*(–ª–µ—Ç|–≥–æ–¥–∞|–º–µ—Å—è—Ü–µ–≤)',
            r'–ª–∏—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.*?(\d+\.?\d*)\s*–¥–æ\s*(\d+\.?\d*)\s*(–ª–µ—Ç|–≥–æ–¥–∞|–º–µ—Å—è—Ü–µ–≤)',
            r'–ª–∏—à–µ–Ω–∏–µ–º –ø—Ä–∞–≤–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.*?–æ—Ç\s*(\d+\.?\d*)\s*–¥–æ\s*(\d+\.?\d*)\s*(–ª–µ—Ç|–≥–æ–¥–∞|–º–µ—Å—è—Ü–µ–≤)',
        ]
        
        license_found = False
        for pattern in license_patterns:
            match = re.search(pattern, article_section, re.IGNORECASE | re.DOTALL)
            if match:
                period_from = match.group(1)
                period_to = match.group(2)
                period_type = match.group(3)
                print(f"   ‚úÖ License suspension: {period_from} - {period_to} {period_type}")
                license_found = True
                break
        
        if not license_found:
            print(f"   ‚ùå Could not extract license suspension period")
        
    except requests.Timeout:
        print(f"‚ùå Request timed out after 10 seconds")
    except requests.RequestException as e:
        print(f"‚ùå Network error: {e}")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


def test_multiple_articles():
    """Test multiple articles"""
    articles = ["12.8", "12.26", "12.9", "12.15"]
    
    for article in articles:
        test_scrape_article(article)
        print("\n" + "-"*60 + "\n")


if __name__ == "__main__":
    print("\nüöÄ –ö–æ–ê–ü Scraper Simple Test\n")
    print("This test will attempt to scrape penalties from consultant.ru")
    print("Make sure you have internet connection!\n")
    
    # Test single article first
    test_scrape_article("12.8")
    
    # Uncomment to test multiple articles
    # test_multiple_articles()
    
    print("\n‚úÖ Test completed!\n")
