"""
Standalone test of –ö–æ–ê–ü scraper (no Django)
"""
import requests
from bs4 import BeautifulSoup
import re

def extract_fine(text):
    """Extract fine amount"""
    patterns = [
        r'(\d+)\s*000\s*—Ä—É–±',
        r'(\d+)\s*—Ç—ã—Å—è—á',
        r'—à—Ç—Ä–∞—Ñ[^\d]*(\d+)\s*000',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            amount = int(match.group(1)) * 1000
            return f"{amount:,} ‚ÇΩ".replace(',', ' ')
    return None

def extract_license_suspension(text):
    """Extract license suspension"""
    patterns = [
        r'–æ—Ç\s*(\d+[,\.]?\d*)\s*–¥–æ\s*(\d+)\s*–ª–µ—Ç',  # "–æ—Ç 1,5 –¥–æ 2 –ª–µ—Ç"
        r'–æ—Ç\s*(\d+[,\.]?\d*)\s*–¥–æ\s*(\d+)\s*–≥–æ–¥–∞',  # "–æ—Ç 1,5 –¥–æ 2 –≥–æ–¥–∞"
        r'–æ—Ç\s*(\d+)\s*–¥–æ\s*(\d+)\s*–º–µ—Å—è—Ü–µ–≤',  # "–æ—Ç 4 –¥–æ 6 –º–µ—Å—è—Ü–µ–≤"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            period_from = match.group(1).replace(',', '.')
            period_to = match.group(2).replace(',', '.')
            if '–º–µ—Å—è—Ü' in match.group(0):
                return f"{period_from}-{period_to} –º–µ—Å—è—Ü–µ–≤"
            else:
                return f"{period_from}-{period_to} –≥–æ–¥–∞"
    return None

def test_article(article_num, url_slug):
    """Test scraping a specific article"""
    url = f"https://shtrafy-gibdd.ru/koap/{url_slug}"
    
    print(f"\n{'='*80}")
    print(f"Testing Article {article_num}")
    print(f"URL: {url}")
    print(f"{'='*80}")
    
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }, timeout=10)
        
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        full_text = soup.get_text()
        
        # Save for debugging
        with open(f'debug_{article_num}.txt', 'w', encoding='utf-8') as f:
            f.write(full_text)
        
        # Extract info
        fine = extract_fine(full_text)
        license_suspension = extract_license_suspension(full_text)
        
        # Debug
        print(f"\nüîç Debug: Searching for license suspension...")
        import re
        test_match = re.search(r'–æ—Ç\s*(\d+[,\.]?\d*)\s*–¥–æ\s*(\d+)\s*–ª–µ—Ç', full_text)
        if test_match:
            print(f"   Found match: {test_match.group(0)}")
            print(f"   Groups: {test_match.groups()}")
        
        print(f"\nüìã Article: —Å—Ç.{article_num} –ö–æ–ê–ü –†–§")
        
        if fine:
            print(f"üí∞ Fine: {fine}")
        else:
            print(f"‚ùå Fine: Not found")
        
        if license_suspension:
            print(f"üö´ License Suspension: {license_suspension}")
        else:
            print(f"‚ùå License Suspension: Not found")
        
        if fine or license_suspension:
            print(f"\n‚úÖ SUCCESS - Data extracted!")
            return True
        else:
            print(f"\n‚ùå FAILED - No data extracted")
            return False
            
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        return False

# Test articles
print("\nüöÄ –ö–æ–ê–ü Scraper Standalone Test")
print("Testing shtrafy-gibdd.ru\n")

results = []
results.append(test_article("12.8", "12-8-1"))
results.append(test_article("12.26", "12-26-1"))

print(f"\n{'='*80}")
print(f"SUMMARY: {sum(results)}/{len(results)} tests passed")
print(f"{'='*80}\n")

if all(results):
    print("‚úÖ All tests PASSED! Scraper is working correctly.\n")
else:
    print("‚ö†Ô∏è  Some tests failed. Check output above.\n")
