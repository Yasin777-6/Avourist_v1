"""
Test article 8.23 (environmental violations)
"""
import requests
from bs4 import BeautifulSoup
import re

def extract_fine(text):
    """Extract fine amount"""
    patterns = [
        r'–æ—Ç\s*(\d+)\s*–¥–æ\s*(\d+)\s*—Ç—ã—Å',
        r'–æ—Ç\s*(\d+)\s*–¥–æ\s*(\d+)\s*000',
        r'(\d+)\s*000\s*—Ä—É–±',
        r'(\d+)\s*—Ç—ã—Å—è—á',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            try:
                if len(match.groups()) >= 2 and match.group(2):
                    amount_from = int(match.group(1)) * 1000
                    amount_to = int(match.group(2)) * 1000
                    return f"{amount_from:,} - {amount_to:,} ‚ÇΩ".replace(',', ' ')
                else:
                    amount = int(match.group(1)) * 1000
                    return f"{amount:,} ‚ÇΩ".replace(',', ' ')
            except:
                pass
    return None

url = "https://shtrafy-gibdd.ru/koap/8-23"

print("="*80)
print("Testing Article 8.23 (Environmental Violations)")
print("="*80)
print(f"URL: {url}\n")

try:
    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
    response.raise_for_status()
    
    soup = BeautifulSoup(response.text, 'html.parser')
    full_text = soup.get_text()
    
    print(f"‚úÖ Fetched successfully")
    print(f"üìÑ Content length: {len(full_text)} bytes\n")
    
    # Extract fine
    fine = extract_fine(full_text)
    
    print(f"üìã Article: —Å—Ç.8.23 –ö–æ–ê–ü –†–§")
    print(f"üìù Title: –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —à—É–º–∞ –∏–ª–∏ –≤—Ä–µ–¥–Ω—ã—Ö –≤—ã–±—Ä–æ—Å–æ–≤\n")
    
    if fine:
        print(f"üí∞ Fine extracted: {fine}")
        print(f"\n‚úÖ SUCCESS - Environmental article scraped correctly!")
    else:
        print(f"‚ùå Fine not found")
        
        # Debug
        if '—à—Ç—Ä–∞—Ñ' in full_text.lower():
            print("\nüîç Found '—à—Ç—Ä–∞—Ñ' in text")
            pos = full_text.lower().find('—à—Ç—Ä–∞—Ñ')
            print(f"Context: ...{full_text[max(0,pos-50):pos+150]}...")
    
except Exception as e:
    print(f"‚ùå Error: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "="*80)
print("This proves the scraper works with ANY –ö–æ–ê–ü chapter!")
print("Not just Chapter 12 (traffic) - also Chapter 8 (environment), etc.")
print("="*80)
