"""
Test scraping from pravo.gov.ru (official government portal)
"""
import requests
from bs4 import BeautifulSoup
import re

def test_pravo_gov():
    """Test fetching –ö–æ–ê–ü from pravo.gov.ru"""
    
    # –ö–æ–ê–ü –†–§ document on pravo.gov.ru
    url = "http://pravo.gov.ru/proxy/ips/?docbody=&nd=102074277"
    
    print("="*80)
    print("Testing pravo.gov.ru (Official Government Legal Portal)")
    print("="*80)
    print(f"\nüì° Fetching: {url}\n")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        print(f"‚úÖ Response: {response.status_code}")
        print(f"üìÑ Content length: {len(response.text)} bytes")
        print(f"üìù Encoding: {response.encoding}\n")
        
        # Parse HTML
        soup = BeautifulSoup(response.text, 'html.parser')
        full_text = soup.get_text()
        
        # Search for article 12.8
        print("üîç Searching for '–°—Ç–∞—Ç—å—è 12.8'...")
        
        pos = full_text.find('–°—Ç–∞—Ç—å—è 12.8')
        if pos == -1:
            pos = full_text.find('—Å—Ç–∞—Ç—å—è 12.8')
        if pos == -1:
            pos = full_text.find('12.8')
        
        if pos != -1:
            print(f"‚úÖ Found at position {pos}\n")
            
            # Extract article section
            article_section = full_text[pos:pos+2000]
            
            print("="*80)
            print("ARTICLE 12.8 TEXT:")
            print("="*80)
            print(article_section[:1000])
            print("="*80)
            
            # Try to extract fine
            print("\nüí∞ Extracting fine amount...")
            fine_patterns = [
                r'(\d+)\s*—Ç—ã—Å—è—á —Ä—É–±–ª–µ–π',
                r'—à—Ç—Ä–∞—Ñ.*?(\d+)\s*—Ç—ã—Å—è—á',
                r'–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–π —à—Ç—Ä–∞—Ñ.*?(\d+)\s*—Ç—ã—Å—è—á',
            ]
            
            for pattern in fine_patterns:
                match = re.search(pattern, article_section, re.IGNORECASE)
                if match:
                    amount = int(match.group(1)) * 1000
                    print(f"   ‚úÖ Fine: {amount:,} ‚ÇΩ".replace(',', ' '))
                    break
            
            # Try to extract license suspension
            print("\nüö´ Extracting license suspension...")
            license_patterns = [
                r'–ª–∏—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.*?–æ—Ç\s*(\d+\.?\d*)\s*–¥–æ\s*(\d+\.?\d*)\s*(–ª–µ—Ç|–≥–æ–¥–∞)',
                r'–ª–∏—à–µ–Ω–∏–µ–º –ø—Ä–∞–≤–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.*?–æ—Ç\s*(\d+\.?\d*)\s*–¥–æ\s*(\d+\.?\d*)\s*(–ª–µ—Ç|–≥–æ–¥–∞)',
            ]
            
            for pattern in license_patterns:
                match = re.search(pattern, article_section, re.IGNORECASE)
                if match:
                    print(f"   ‚úÖ License: {match.group(1)} - {match.group(2)} {match.group(3)}")
                    break
            
        else:
            print("‚ùå Article 12.8 not found")
            print("\nüìù Sample content (first 1000 chars):")
            print(full_text[:1000])
        
    except requests.Timeout:
        print("‚ùå Request timed out")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


def test_alternative_sources():
    """Test alternative –ö–æ–ê–ü sources"""
    
    sources = [
        ("pravo.gov.ru", "http://pravo.gov.ru/proxy/ips/?docbody=&nd=102074277"),
        ("garant.ru", "https://base.garant.ru/12125267/"),
        ("kodeks.ru", "https://docs.cntd.ru/document/901807664"),
    ]
    
    print("\n\n" + "="*80)
    print("Testing Alternative Legal Sources")
    print("="*80)
    
    for name, url in sources:
        print(f"\nüì° Testing {name}...")
        try:
            response = requests.get(url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0'
            })
            if response.status_code == 200:
                if '12.8' in response.text:
                    print(f"   ‚úÖ {name}: Accessible, contains –ö–æ–ê–ü content")
                else:
                    print(f"   ‚ö†Ô∏è  {name}: Accessible but –ö–æ–ê–ü not found")
            else:
                print(f"   ‚ùå {name}: HTTP {response.status_code}")
        except Exception as e:
            print(f"   ‚ùå {name}: {str(e)[:50]}")


if __name__ == "__main__":
    print("\nüöÄ Testing Official Government Legal Portal\n")
    
    test_pravo_gov()
    test_alternative_sources()
    
    print("\n\n‚úÖ Test completed!\n")
